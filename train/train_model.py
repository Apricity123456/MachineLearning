import os
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report
from sklearn.preprocessing import StandardScaler
import joblib

# === è‡ªåŠ¨è·å–è·¯å¾„ ===
base_dir = os.path.dirname(os.path.abspath(__file__))
features_path = os.path.join(base_dir, "features_with_shape.csv")
labels_path = os.path.join(base_dir, "classif.xlsx")
models_dir = os.path.join(base_dir, "models")

# åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
os.makedirs(models_dir, exist_ok=True)

# === åŠ è½½æ•°æ® ===
features_df = pd.read_csv(features_path)
labels_df = pd.read_excel(labels_path)

# === å¤„ç† ID æ ¼å¼ ===
features_df['ID'] = features_df['ID'].astype(str).str.extract(r'(\d+)')[0].astype(int)
labels_df['ID'] = labels_df['ID'].astype(str).str.extract(r'(\d+)')[0].astype(int)
labels_df = labels_df.rename(columns={"bug type": "bug_type"})

# === åˆå¹¶æ•°æ® & æ¸…æ´—ç±»åˆ« ===
df = pd.merge(features_df, labels_df[['ID', 'bug_type']], on='ID')
counts = df['bug_type'].value_counts()
df = df[df['bug_type'].isin(counts[counts >= 2].index)]

# === ç‰¹å¾ä¸æ ‡ç­¾æ‹†åˆ† ===
X = df.drop(columns=["ID", "bug_type"])
y = df["bug_type"]

# === ç‰¹å¾æ ‡å‡†åŒ–ï¼ˆé‡è¦ï¼ä¸ºé€»è¾‘å›å½’å’ŒSVMæå‡æ€§èƒ½ï¼‰===
scaler = StandardScaler()
X = scaler.fit_transform(X)

# === æ‹†åˆ†è®­ç»ƒé›† ===
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# === æ¨¡å‹é›†åˆï¼ˆç›‘ç£å­¦ä¹ ï¼‰===
models = {
    "random_forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "svm": SVC(kernel='rbf', probability=True, random_state=42),
    "knn": KNeighborsClassifier(n_neighbors=3),
    "logistic_regression": LogisticRegression(max_iter=1000, random_state=42)
}

# === æ‰“å°äº¤å‰éªŒè¯å¾—åˆ† & ä¿å­˜æ¨¡å‹ ===
print("ğŸ“Š ç›‘ç£å­¦ä¹ æ¨¡å‹äº¤å‰éªŒè¯å‡†ç¡®ç‡ï¼š")
for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
    print(f"{name.capitalize()}: å‡†ç¡®ç‡å‡å€¼={scores.mean():.3f}ï¼Œæ ‡å‡†å·®={scores.std():.3f}")
    
    model.fit(X_train, y_train)
    model_path = os.path.join(models_dir, f"model_{name}.pkl")
    joblib.dump(model, model_path)
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜ä¸º: {model_path}")

# === éç›‘ç£å­¦ä¹ ï¼šKMeans èšç±» ===
print("\nğŸ” éç›‘ç£å­¦ä¹ ï¼šKMeans èšç±»")
kmeans = KMeans(n_clusters=len(y.unique()), n_init=10, random_state=42)
clusters = kmeans.fit_predict(X)
df['cluster'] = clusters
print(df[['ID', 'bug_type', 'cluster']].head())
